{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89aafc9c",
   "metadata": {},
   "source": [
    "Sequential Tool Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d350d1f1",
   "metadata": {},
   "source": [
    "The LLM decides when to call another tool and which tool to call next in a seq task instead of hardcoding the sequence\n",
    "\n",
    "LLM => Tool Call => State Update => LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37097a70",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Tools\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers and return the product.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "def translate_to_french(text: str) -> str:\n",
    "    \"\"\"Return a mock French translation of the input text.\"\"\"\n",
    "    return f\"French translation of '{text}'\"\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Return a mock weather string for the given city.\"\"\"\n",
    "    return f\"The weather in {city} is sunny.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcecadce",
   "metadata": {},
   "source": [
    "Each tool needs a short docstring so LangGraph can wrap it correctly as a StructuredTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64bcbad",
   "metadata": {},
   "source": [
    "LangGraph WorkFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627f6594",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb3afcf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# State that holds conversation history\n",
    "class MyMessagesState(MessagesState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f6b35",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# LLM with all tools bound\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools([multiply, translate_to_french, get_weather])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8d2815",
   "metadata": {},
   "source": [
    "LLM node: Listens to the conversation and may produce a tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb6d89f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Node: AI generates a response and may request a tool\n",
    "def tool_calling_llm(state: MyMessagesState):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f466be23",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Build the graph\n",
    "builder = StateGraph(MyMessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660e6d1c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode([multiply, translate_to_french, get_weather]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717fb0ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Flow: START -> LLM\n",
    "builder.add_edge(START, \"tool_calling_llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c4ee55",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# LLM -> tools OR END\n",
    "builder.add_conditional_edges(\"tool_calling_llm\", tools_condition, {\"tools\": \"tools\", \"default\": END})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9fe3d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# After tool execution, return to LLM for possible next step\n",
    "builder.add_edge(\"tools\", \"tool_calling_llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587c3f29",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6da3be",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6baab7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Multi-step example: requires get_weather THEN translate_to_french\n",
    "messages = graph.invoke({\"messages\": [HumanMessage(content=\"Translate the weather in Paris into French\")]})\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a496c793",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Single-step example\n",
    "messages = graph.invoke({\"messages\": [HumanMessage(content=\"Multiply 2 and 3\")]})\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
