{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dafaa3b8",
   "metadata": {},
   "source": [
    "Conversations and Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5903d",
   "metadata": {},
   "source": [
    "Stores and automatically handles conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e61bf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class MyMessagesState(MessagesState):\n",
    "    # Inherits from MessagesState, which automatically handles adding messages\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84817e7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#llm\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")  # Just an example model name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426c83dc",
   "metadata": {},
   "source": [
    "Adding Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aca7c5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    return a * b\n",
    "    \n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c97209e",
   "metadata": {},
   "source": [
    "Creating a Node for ai processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1b0bd9",
   "metadata": {},
   "source": [
    "1 -Reads the entire conversation from state[\"messages\"].\n",
    "\n",
    "2 -Invokes llm_with_tools to generate a response, considering all past messages.\n",
    "\n",
    "3 -Returns that new message so it’s appended to the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c230e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def tool_calling_llm(state: MyMessagesState):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93de65e",
   "metadata": {},
   "source": [
    "Build a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b6291",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b91d50a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "builder = StateGraph(MyMessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5114d01c",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c6871",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello!\")})\n",
    "for m in messages['messages']:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe7a842",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiply 2 and 3\")})\n",
    "for m in messages['messages']:\n",
    "  print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58755293",
   "metadata": {},
   "source": [
    "Dynamic Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5c4c4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8ac1a3",
   "metadata": {},
   "source": [
    "1 - ToolNode: A prebuilt node provided by LangGraph that executes tools. Think of it as a designated area in our dinner party where a specialized assistant, such as a math expert, works.\n",
    "\n",
    "2 - tools_condition: A prebuilt condition that examines the AI’s latest response to determine whether it includes a tool call. It is like a decision-maker who looks at the conversation and decides whether to send a request to the math expert or continue the conversation normally. When it detects a tool call, it automatically routes to a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93028828",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "\n",
    "# A ToolNode automatically handles executing any tool calls made by the LLM\n",
    "builder.add_node(\"tools\", ToolNode([multiply]))\n",
    "\n",
    "# Connect the start to our LLM node\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "\n",
    "# Add a conditional edge that uses 'tools_condition'\n",
    "# If the LLM’s response indicates a tool call, it routes to \"tools\"\n",
    "# Otherwise, it routes to END\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "builder.add_edge(\"tools\", END)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2755212c",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af2179",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [HumanMessage(content=\"Multiply 3 and 2\")]\n",
    "messages = graph.invoke({\"messages\": messages})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b042c6fe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [HumanMessage(content=\"Hello world.\")]\n",
    "messages = graph.invoke({\"messages\": messages})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
