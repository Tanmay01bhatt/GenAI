{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "990709e6",
   "metadata": {},
   "source": [
    "Error Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a10166",
   "metadata": {},
   "source": [
    "Nodes are where you decide policy: how many retries, what fallback message, what error to surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f26c19f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658277b4",
   "metadata": {},
   "source": [
    "Paris always works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7325ed3b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def weather_paris(state: MyMessagesState):\n",
    "    text = get_weather(\"Paris\")\n",
    "    return {\"messages\": [AIMessage(content=text)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c10e6",
   "metadata": {},
   "source": [
    "1 - First attempt for London. If it succeeds, we’re done.\n",
    "\n",
    "2 - If it fails, we retry once.\n",
    "\n",
    "3 - If the retry fails again, we gracefully degrade with a clear placeholder.(so that the assistant doesn’t hallucinate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a663c7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def weather_london(state: MyMessagesState):\n",
    "    try:\n",
    "        # First attempt\n",
    "        text = get_weather(\"London\")\n",
    "        return {\"messages\": [AIMessage(content=text)]}\n",
    "    except Exception as e:\n",
    "        # Retry once\n",
    "        try:\n",
    "            text = get_weather(\"London\")\n",
    "            return {\"messages\": [AIMessage(content=text)]}\n",
    "        except Exception:\n",
    "            # Fallback if still failing\n",
    "            return {\"messages\": [AIMessage(content=\"London weather is currently unavailable.\")]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ce47f",
   "metadata": {},
   "source": [
    "Parallel Routing/Tool calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0812279a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def parallel_weather_condition(state: MyMessagesState):\n",
    "    last_human = \"\"\n",
    "    for msg in reversed(state[\"messages\"]):\n",
    "        if getattr(msg, \"type\", \"\") == \"human\":\n",
    "            last_human = (msg.content or \"\").lower()\n",
    "            break\n",
    "\n",
    "    targets = []\n",
    "    if \"paris\" in last_human:\n",
    "        targets.append(\"weather_paris\")\n",
    "    if \"london\" in last_human:\n",
    "        targets.append(\"weather_london\")\n",
    "\n",
    "    if not targets:\n",
    "        targets = [\"weather_paris\"]\n",
    "\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbdaddc",
   "metadata": {},
   "source": [
    "The join node needs to accept both real tool outputs and fallback messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db26bff2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def combine_weather(state: MyMessagesState):\n",
    "    lines = []\n",
    "    for m in state[\"messages\"]:\n",
    "        if isinstance(m, AIMessage) and isinstance(m.content, str):\n",
    "            if \"The weather in\" in m.content or \"unavailable\" in m.content:\n",
    "                lines.append(m.content)\n",
    "\n",
    "    combined = \" | \".join(lines) if lines else \"No weather data found.\" #Deterministic join: We concatenate lines so learners can predict the behavior.\n",
    "    return {\"messages\": [AIMessage(content=f\"Combined: {combined}\")]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62311ca",
   "metadata": {},
   "source": [
    "We can replace the simple deterministic join step with an LLM summarizer to enhance the final text without changing the overall workflow structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f9428",
   "metadata": {},
   "source": [
    "Graph WorkFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce4364",
   "metadata": {},
   "source": [
    " START → LLM → conditional → parallel branches → join → END "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7768742c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be35a0a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "builder = StateGraph(MyMessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c19d9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"weather_paris\", weather_paris)\n",
    "builder.add_node(\"weather_london\", weather_london)\n",
    "builder.add_node(\"combine_weather\", combine_weather)\n",
    "\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\"tool_calling_llm\", parallel_weather_condition)\n",
    "builder.add_edge(\"weather_paris\", \"combine_weather\")\n",
    "builder.add_edge(\"weather_london\", \"combine_weather\")\n",
    "builder.add_edge(\"combine_weather\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb5d39e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506f857c",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cff5f43",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "print(\"\\n================= Test 1: Paris AND London =================\")\n",
    "res = graph.invoke({\"messages\": [HumanMessage(content=\"What's the weather in Paris and London?\")]})\n",
    "for m in res[\"messages\"]:\n",
    "    m.pretty_print()\n",
    "\n",
    "print(\"\\n================= Test 2: Paris only =================\")\n",
    "res = graph.invoke({\"messages\": [HumanMessage(content=\"What's the weather in Paris?\")]})\n",
    "for m in res[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
